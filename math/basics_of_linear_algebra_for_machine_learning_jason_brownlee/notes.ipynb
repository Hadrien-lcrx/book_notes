{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e091d0c-3033-4106-9845-2ff92fd38929",
   "metadata": {},
   "source": [
    "# Basics of linear algebra for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b028fdb-fa30-44d4-b36e-59dff81621ac",
   "metadata": {},
   "source": [
    "## 01 - Introduction to linear algebra\n",
    "### Linear algebra\n",
    "Linear algebra is about linear combinations: using arithmetic on columns of numbers (vectors) and arrays of numbers (matrices) to create new columns and arrays of numbers. It's been formalized in the 1800s to find unknowns in systems of linear equations. \n",
    "\n",
    "A linear equation is a series of terms and mathematical operations where some terms are unknown, for example:  \n",
    "$y = 4 x + 1$\n",
    "\n",
    "They are called linear equations because they describe a line on a two-dimensional graph. We can line up a system of equations with two or more unknowns:  \n",
    "- $y = 0.1 x_{1} + 0.4 x_{2}$  \n",
    "- $y = 0.3 x_{1} + 0.9 x_{2}$  \n",
    "- $y = 0.2 x_{1} + 0.3 x_{2}$\n",
    "\n",
    "where:\n",
    "- the column of $y$ values is a column vector of outputs from the equation\n",
    "- the two columns of float values are the data columns $a_{1}$ and $a_{2}$ forming the matrix $A$\n",
    "- the two unknown values $x_{1}$ and $x_{2}$ are the coefficients of the equation and form a vector of unknowns $b$ to be solved\n",
    "\n",
    "summarized in linear algebra as:  \n",
    "$y = A \\cdot b$\n",
    "\n",
    "Such problems are challenging to solve because:\n",
    "- there are usually more unknowns than there are equations to solve\n",
    "- no single line can satisfy all of the equations without error\n",
    "\n",
    "Interesting problems are often described by system with an infinite number of solutions. This is the core of linear algebra as it relates to machine learning. The rest of the operations are about making such problems easier to understand and solve.\n",
    "\n",
    "### Numerical linear algebra\n",
    "Implementations of vector and matrix operations were initially implemented in FORTRAN with libraries such as:\n",
    "- LAPACK\n",
    "- BLAS\n",
    "- ATLAS\n",
    "\n",
    "Popular packages used nowadays in Python for example build on top of these libraries.\n",
    "\n",
    "### Linear algebra and statistics\n",
    "- using vector and matrix notation (multivariate statistics)\n",
    "- solving least squares and weighted least squares (linear regression)\n",
    "- estimating means and variance of data matrices\n",
    "- using the covariance matrix (multinomial Gaussian distributions)\n",
    "- leveraging the concepts above for data reduction with principal component analysis\n",
    "\n",
    "### Applications of linear algebra\n",
    "- matrices in engineering (line of springs)\n",
    "- graphs and networks (graph analysis)\n",
    "- Markov matrices, population, economics (population growth)\n",
    "- linear programming (simplex optimization method)\n",
    "- Fourier series - linear algebra for functions (signal processing)\n",
    "- linear algebra for statistics and probabilities (least squares for regression)\n",
    "- computer graphics (translation, rescaling, rotation of images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1b683-0fa7-47bf-8f81-242afe2a145b",
   "metadata": {},
   "source": [
    "## 02 - Linear algebra and machine learning\n",
    "Linear algebra is the mathematics of data. Often recommended as a prerequisite to machine learning, it can make more sense to first build context of the applied machine learning process.\n",
    "\n",
    "### Reasons not to learn linear algebra\n",
    "- it's not required in order to use machine learning as a tool to solve problems\n",
    "- it's slow and might delay you achieving your goals\n",
    "- it's a huge field and not all of it is relevant to machine learning\n",
    "\n",
    "A breadth-first (results-first) approach can help build a skeleton and some context on which to build to deepen knowledge about how algorithms work or the math that underlies them.\n",
    "\n",
    "### Linear algebra notation\n",
    "You need to know how to read and write vector and matrix notation. It enables you to:\n",
    "- describe operations on data precisely\n",
    "- read descriptions of algorithms in textbooks\n",
    "- implement machine learning algorithms faster and more efficiently\n",
    "- interpret and implement new methods in research papers\n",
    "- describe your own methods to other practitioners\n",
    "\n",
    "### Linear algebra arithmetic\n",
    "You need to know how to perform arithmetic operations: add, subtract and multiply scalars, vectors and matrices. Matrix multiplication and tensor multiplication are often non-intuitive at first. Understanding vector and matrix operations is required to effectively read and write matrix notation.\n",
    "\n",
    "### Learn linear algebra for statistics\n",
    "Linear algebra is heavily used in multivariate statistics. To read and interpret statistics, you need to know the notation and operations of linear algebra, such as vectors used for means and variance, or covariance matrices describing the relationships between multiple Gaussian variables. Principal component analysis also leverages such methods.\n",
    "\n",
    "### Learn matrix factorization\n",
    "Matrix factorization, is also called matrix decomposition. You need to know how to factorize a matrix and what it means. Matrix factorization is necessary for more complex operations in linear algebra (matrix inverse) and machine learning (least squares). Different matrix factorization exist, such as singular-value decomposition. To read and interpret higher-order matrix operations, matrix factorization is required.\n",
    "\n",
    "### Learn linear least squares\n",
    "Matrix factorization can be used to solve linear least squares. Problems where there is no line able to fit the data without error can be solved using the least squares method, called linear least squares in linear algebra. Linear least squares are used in regression models, and in a range of machine learning algorithms.\n",
    "\n",
    "### One more reason\n",
    "Seeing how the operations work on real data will help you develop a strong intuition for the methods. You will experience knowledge buzz and mind-expanding moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483522cf-79ce-470c-bc69-b7146a03b690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
